\documentclass[11pt,twocolumn]{article}

\usepackage{hyperref}
\usepackage{fullpage}

\linespread{1.2}

\begin{document}

\title{CSE 549\\Computational Biology -- Project Proposal\\Genome Compression}
\author{Pragya Pande \and Dhruv Matani}
\date{\today}

\maketitle

\vspace{0.5in}

\section*{The problem}
The Complete Human Genome was sequenced in 2003. Since then a lot of
research is being done in genomics and computational biology. The
major input for most of the computation is the 2.9 billion base pairs
\cite{2}\cite{3} of the human genome which correspond to a maximum of about 
725 megabytes of data human genome.\cite{4}

Furthermore, reduction in the cost of sequencing(via the “next-gen” 
sequencing platforms),has given birth to the 1000 genome project
(1000genomes.org) which aims to sequence the genomes of a large 
number of people. Just like the other human genome reference projects,
this data (estimated 8.2 billion bases per day) would be made
available via public databases for the scientific community.\cite{5}

As we can now see, we are dealing with megabytes and megabytes of data 
when we do work with genomes! This has resulted in rise to challenging 
problems with respect tostorage, distribution (downloading, copying), 
and sharing of this genomic data. Hence we need to consider better 
compression techniques for the genomic data.

In this project, we explore this problem of genome compression and see
if we can compress the human genome to more than what the previous
researcher have done.\cite{6}

\section*{Applicability}

The goal of the 1000 genomes project\footnote{\url{http://www.1000genomes.org/}}
is to find most genetic variants that have frequencies of at least 1\%
in the populations studied. Similarly, once the \$1000 genome
project\cite{1000genomeproject} becomes successful, storage costs for
all the sequenced genomes will need to be kept under control. To be
able to do this, we need an space (and time) efficient way of
compressing the sequenced genomes so that the DNA of more people can
be sequenced for a reasonable price.



\section*{Current work}

A group of researchers from The University of California at Irvine
lead by Dr. Chen Li\footnote{http://www.ics.uci.edu/\textasciitilde{}chenli/} have
researched the compressibility of the human genome against a reference
genome and have achieved fascinating results\cite{dnazip}. They have been able to
compress James Watson's genome\footnote{James Watson's genome is a
  418MiB compressed downloadable tarball} which is 3 billion base
pairs long to about 4MB of compressed data. This is small enough to be
emailed across the globe!

They have used the repititive nature of the genomic data to their
advantage to aid compression. Also, since the genomes of most humans
differs in approximately 1 base pair in about 1000, there are a lot of
gains to be had by compressing a human genome it against a reference
human genome.

Their technique relies on a few key
observations\cite{genomecompressionchenli}:

\begin{enumerate}

\item \textbf{Variable integers for positions (VINT)}: Chromosome
  sizes can vary. Some can be up to 250MiB in size. Representing
  offsets within these files would require 4 bytes. However, many
  smaller offsets don't need such large integers to store the
  data. Variable size integers are helpful in such situations.

\item \textbf{Delta positions (DELTA)}: The idea of storing delta
  offsets v/s absolute offsets seems to be one borrowed from
  run-length encoding of strings where repetitive patterns are stored
  as offsets relative to where they last occured.

\end{enumerate}

\subsection*{}

\section*{The plan}

\subsection*{Getting the data}

We plan on using the same data that the previous research group from
UC Irvine has used so that we can compare the compression achieved by
our technique against theirs.

The various data sets used by the researchers are:

\begin{enumerate}

\item The human reference genome\footnote{Compressed size is
  840MiB}. This is used as the reference genome against which
  differences are compared. There are 25 FASTA files, one for each
  chromosome and the mitochondrial genome.

\item dbSNP database, used as the refernece SNP\footnote{A
  Single-nucleotide polymorphism is a DNA sequence variation occurring
  when a single nucleotide - A, T, C or G - in the genome (or other
  shared sequence) differs between members of a biological species or
  paired chromosomes in an individual} map.


\end{enumerate}


\subsection*{Handling FASTA files}


\subsection*{Rough estimates of compressibility}

\clearpage

\begin{thebibliography}{9}

\bibitem{dnazip}
DNAzip: DNA sequence compression using a reference genome
\url{http://www.ics.uci.edu/~dnazip/}
\bibitem{2}
http://www.strategicgenomics.com/Genome/index.htm
\bibitem{3}
http://www.nature.com/nature/journal/v431/n7011/abs/nature03001.html
\bibitem{4}
http://en.wikipedia.org/wiki/Human\_genome
\bibitem{5}
http://www.1000genomes.org/about
\bibitem{6}
http://bioinformatics.oxfordjournals.org/content/25/2/274.full

\bibitem{1000genomeproject}
Anticipating the 1,000 dollar genome.
Mardis ER

\bibitem{genomecompressionchenli}
Human genomes as email attachments.
Scott Christley, Yiming Lu, Chen Li, \and Xiaohui Xie


\end{thebibliography}



\end{document}
